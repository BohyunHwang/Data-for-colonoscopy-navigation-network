The src directory contains all core scripts required for training, validating, visualizing, and interpreting the autonomous colonoscopy Enhanced Navigation model.
Each script serves a dedicated role, ranging from model training to prediction analysis and Grad-CAM explainability.

Running main.py will start the training process.

1. main.py : Training & Pipeline orchestration
  This is the central script that manages the entire training workflow
  - Initializes the model from models.py gen_model()
  - Loads training/validation datasets
  - Performs epoch-wise training and validation loops
  - Tracks losses and metrices (regression loss, classification loss, F1-score)
  - Saves the best_model.pth checkpoint
  - Logs learning curves and output loss visualization
  - Automatically runs plot_prediction.py after training for validation
  This is the primary entry point for model development.
2. model.py : Model Generation
  The model.py script serves as a model factory that builds the neural network architecture specified in the training options.
  It provides a unified interface for loading various backbone modules located inside the models/ directory.
  - Selects and initializes the model using gen_model(args, device)
  - Supports multiple architectures, enabling users to easily switch between different deep-learning backbones
  - Ensures the model is correctly placed on CPU/GPU
  Supported Models (via models/ folder): The models/ directory includes several different architectures for autonomous colonoscopy navigation.
  Although CNN is commonly used, the framework allows selecting other models for experimentation:
3. opt.py : Configuration & Argument Parser
  Defines all configurable hyperparameters and paths:
  - Dataset path, model output path
  - Training parameters (epoch, batch size, LR)
  - Network dimensions (hidden size, dropout, embedding size)
  - Sequence length and target length (If seq2seq and/or lstm architecture is selected for training)
  - CUDA enabling/disabling
  This script allows users to control the entire training pipeline via CLI
4. plot_prediction.py : Validation, Evaluation and Visualization
  This script performs full validation ujsing the trained best model:
  - Loads best_model.pth
  - Generates predictions for each testing sequence
  - Computes: Total Loss, Regression loss, Classification loss, Accuracy, F1-score, Confusion matrix, RMSE
  - Plots: Steering x/y: ground-truth vs prediction curves, collision labels vs predicted labels
  - Saves all evaluation figures for analysis
5. check_points.py : Ground-truth vs inference comparison
  Provides qualitative visual comparison between ground-truth steering targets (label CSV) and Predicted coordinates(*_pred.npy generated by inference)
  For each image: plots GT target and Predicted target on the original frame. Saves overlay images for quick inspection.
6. CNN_grad-cam_Classification.py and CNN_grad-cam_Regression.py : Explainability for collision classification and steering regression
  - Produces CAM maps for X and Y predictions separately
  - Generates combined heatmaps showing spatial attention
  - Helps understand which image regions influence steering decisions
